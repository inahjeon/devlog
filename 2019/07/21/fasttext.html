<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>FastText Pre-trained 한국어 모델 사용기 | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="FastText Pre-trained 한국어 모델 사용기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. FastText 소개" />
<meta property="og:description" content="1. FastText 소개" />
<link rel="canonical" href="https://inahjeon.github.io/devlog/2019/07/21/fasttext.html" />
<meta property="og:url" content="https://inahjeon.github.io/devlog/2019/07/21/fasttext.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-21T19:55:00-05:00" />
<script type="application/ld+json">
{"description":"1. FastText 소개","headline":"FastText Pre-trained 한국어 모델 사용기","dateModified":"2019-07-21T19:55:00-05:00","datePublished":"2019-07-21T19:55:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://inahjeon.github.io/devlog/2019/07/21/fasttext.html"},"url":"https://inahjeon.github.io/devlog/2019/07/21/fasttext.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/devlog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://inahjeon.github.io/devlog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/devlog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>FastText Pre-trained 한국어 모델 사용기 | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="FastText Pre-trained 한국어 모델 사용기" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. FastText 소개" />
<meta property="og:description" content="1. FastText 소개" />
<link rel="canonical" href="https://inahjeon.github.io/devlog/2019/07/21/fasttext.html" />
<meta property="og:url" content="https://inahjeon.github.io/devlog/2019/07/21/fasttext.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-07-21T19:55:00-05:00" />
<script type="application/ld+json">
{"description":"1. FastText 소개","headline":"FastText Pre-trained 한국어 모델 사용기","dateModified":"2019-07-21T19:55:00-05:00","datePublished":"2019-07-21T19:55:00-05:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://inahjeon.github.io/devlog/2019/07/21/fasttext.html"},"url":"https://inahjeon.github.io/devlog/2019/07/21/fasttext.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://inahjeon.github.io/devlog/feed.xml" title="fastpages" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/devlog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/devlog/about/">About Me</a><a class="page-link" href="/devlog/search/">Search</a><a class="page-link" href="/devlog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">FastText Pre-trained 한국어 모델 사용기</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2019-07-21T19:55:00-05:00" itemprop="datePublished">
        Jul 21, 2019
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="1-fasttext-소개">1. FastText 소개</h2>

<p><a href="https://fasttext.cc/">FastText</a>는 Facebook에서 만든 word representation 과 sentence classification의 효율적인 학습을 위한 라이브러리입니다.</p>

<p>일반적으로 자연어처리에서 말뭉치 사전 데이터 수집하고 전처리하는 데 많은 시간이 소요됩니다.</p>

<p>그런데 facebook에서 <code class="highlighter-rouge">fasttext</code>를 소개하면서 무려 <code class="highlighter-rouge">157개국</code>의 언어에 대해 common crawler와 wikipedia의 데이터를 학습한 <code class="highlighter-rouge">Pre-trained model</code>을 제공하고 있습니다.</p>
<blockquote>
  <p>한국어도 제공하고 있습니다. 만세!</p>
</blockquote>

<p>글에서는 미리 훈련된 데이터가 어느정도 성능이 나올 지 테스트 해보았습니다.</p>

<h2 id="2-fast-text-설치-및-pre-trained-모델-다운받기">2. Fast Text 설치 및 pre-trained 모델 다운받기</h2>

<p>FastText는 공개된 github 저장소 <a href="https://github.com/facebookresearch/fastText.git">https://github.com/facebookresearch/fastText.git</a>를 clone해서 하거나, <a href="https://radimrehurek.com/gensim/">gensim</a> 이라는 파이썬 패키지에 포함되어 있어 <code class="highlighter-rouge">gensim</code>을 설치해서 사용할 수 있습니다.</p>

<p>여기서는 <code class="highlighter-rouge">gensim</code>을 설치해서 사용해보았습니다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install gensim
</code></pre></div></div>

<p>미리 훈련된 한국어 모델은 데이터는 <a href="https://fasttext.cc/docs/en/crawl-vectors.html">https://fasttext.cc/docs/en/crawl-vectors.html</a>에서 제공하고 있습니다.</p>

<p>모델은 <code class="highlighter-rouge">.vec</code> <code class="highlighter-rouge">.bin</code> 의 두 가지 형태의 파일로 제공 하고 있는데, <code class="highlighter-rouge">.vec</code> 파일은 라인마다 단어에 대한 vector가 있는 형태이고 <code class="highlighter-rouge">.bin</code> 파일은 벡터 뿐만 아니라 dictionary와 모델의 하이퍼 파라미터와 같은 정보들이 모두 들어있는 형태입니다.</p>

<p>binary 파일을 사용하면 모델을 추가로 학습해서 개선할 수 있다고 합니다.</p>

<p>둘다 다운 받고 압축을 풀었보았습니다. (모델을 읽어서 쓸 때는 굳이 압축을 풀지 않고 사용해도 됩니다.)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gunzip cc.ko.300.vec.gz
gunzip cc.ko.300.bin.gz
</code></pre></div></div>

<p>(압축을 푸니 <code class="highlighter-rouge">gunzip cc.ko.300.vec</code> 은 4.5GB, <code class="highlighter-rouge">gunzip cc.ko.300.bin</code> 은 7.2GB로 용량이 매우 컸습니다. ㄷㄷ)</p>

<h2 id="3-pre-trained-한국어-모델-적용">3. Pre-trained 한국어 모델 적용</h2>

<h3 id="미리-훈련된-모델로-비슷한-단어-추출해보기">미리 훈련된 모델로 비슷한 단어 추출해보기</h3>

<p>훈련된 모델을 이용해서 <code class="highlighter-rouge">파이썬</code> 이라는 단어와 유사한 단어를 출력해보았습니다.</p>

<p>모델 파일의 크기가 매우 커서 그런지 모델을 로딩하는 시간이 거의 3분~4분 정도 걸립니다. (테스트 할때마다 시간이 오래걸려, 코드를 짤 때는 다른 테스트용 모델로 작업하고 모델만 바꿔서 돌렸습니다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">models</span>

<span class="n">ko_model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">fasttext</span><span class="o">.</span><span class="n">load_facebook_model</span><span class="p">(</span><span class="s">'cc.ko.300.bin'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">m_fasttext</span><span class="o">.</span><span class="n">similar_by_word</span><span class="p">(</span><span class="s">'파이썬'</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'{w}: {sim}'</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">파이썬</code>과 유사한 단어 결과:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Python: 0.565061628818512
자이썬: 0.5624369382858276
레일스: 0.5598082542419434
파이썬을: 0.5595801472663879
언어용: 0.5288202166557312
파이썬의: 0.5250024795532227
프로그래밍: 0.5225088000297546
wxPython: 0.5222088098526001
파이썬이나: 0.5201171636581421
함수형: 0.5187377333641052
</code></pre></div></div>

<p><code class="highlighter-rouge">아이언맨</code>과 유사한 단어 결과:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>아이언맨2: 0.6507514119148254
아이언맨과: 0.6068165302276611
아이언맨에: 0.5806230306625366
아이언맨의: 0.5622424483299255
스파이더맨: 0.5526455044746399
아이언맨3: 0.5465470552444458
아이언맨은: 0.5207207798957825
가디언즈오브갤럭시: 0.5029110908508301
헐크버스터: 0.5008623600006104
어벤져스: 0.4941202402114868
</code></pre></div></div>

<h3 id="단어-간-유사도-비교">단어 간 유사도 비교</h3>

<p>다음과 같이 단어의 유사도도 쉽게 비교해 볼 수 있습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"'아이언맨'과 '헐크'의 유사도: {m_fasttext.similarity('아이언맨', '헐크')}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"'아이언맨'과 '스파이더맨'의 유사도: {m_fasttext.similarity('아이언맨', '스파이더맨')}"</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'아이언맨'과 '헐크'의 유사도: 0.4033605754375458
'아이언맨'과 '스파이더맨'의 유사도: 0.5526454448699951
</code></pre></div></div>

<p><del>아이언맨은 스파이더맨과 더 친한 것으로..</del></p>

<h3 id="단어-벡터-시각화">단어 벡터 시각화</h3>

<p>이번에는 차원축소기법인 PCA를 사용해서 단어 벡터들을 2차원으로 축소시키고, 다음과 같이 2차원 그래프에 표현해보았습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">words</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'사과'</span><span class="p">,</span>
    <span class="s">'바나나'</span><span class="p">,</span>
    <span class="s">'오렌지'</span><span class="p">,</span>
    <span class="s">'키위'</span><span class="p">,</span>
    <span class="s">'스파이더맨'</span><span class="p">,</span> 
    <span class="s">'아이언맨'</span><span class="p">,</span> 
    <span class="s">'헐크'</span><span class="p">,</span>
    <span class="s">'타노스'</span><span class="p">,</span>
    <span class="s">'캡틴아메리카'</span><span class="p">,</span>
    <span class="s">'어벤져스'</span>
<span class="p">]</span>
<span class="c1"># matplotplib 폰트 설정을 안해서 그래프에서 한국어 라벨이 깨져서 아래 단어로 임시처리했습니다. ㅠ
</span><span class="n">word_labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'apple'</span><span class="p">,</span>
    <span class="s">'banana'</span><span class="p">,</span>
    <span class="s">'orange'</span><span class="p">,</span>
    <span class="s">'kiwi'</span><span class="p">,</span>
    <span class="s">'spider man'</span><span class="p">,</span> 
    <span class="s">'iron man'</span><span class="p">,</span> 
    <span class="s">'hulk'</span><span class="p">,</span>
    <span class="s">'thanos'</span><span class="p">,</span>
    <span class="s">'captin america'</span><span class="p">,</span>
    <span class="s">'avengers'</span>
<span class="p">]</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">xys</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">m_fasttext</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">word_vec</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">])</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">xys</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">xys</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_labels</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ys</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</code></pre></div></div>

<p>결과:</p>

<p><img src="https://user-images.githubusercontent.com/16538186/61593363-82323880-ac19-11e9-8df1-8a3831a0e679.png" alt="" /></p>

<p>그래프에서 <code class="highlighter-rouge">사과</code>, <code class="highlighter-rouge">바나나</code>, <code class="highlighter-rouge">키위</code> 같은 과일 단어들은 그리 가깝게 뭉쳐지진 않았지만, <code class="highlighter-rouge">아이언앤</code>, <code class="highlighter-rouge">스파이더맨</code>, <code class="highlighter-rouge">어벤져스</code> 등의 특정 고유명사들은 연관된 단어들끼리 잘 뭉쳐진 걸 확인할 수 있었습니다. (왠일인지 <code class="highlighter-rouge">헐크</code>는 저멀리 떨어져 있지만…)</p>

<h2 id="느낀점">느낀점</h2>

<ul>
  <li>pre-trained 모델이 생각보다 괜찮은 것 같은데, 모델을 로딩하는 시간이 매우 느립니다. ㅠ</li>
  <li>훈련된 모델에 데이터를 추가해서 더 학습이 가능한 걸로 보여서 특정 도메인에 맞는 학습 데이터를 더 수집해서 성능을 비교해보면 좋을 것 같습니다.</li>
  <li>fasttext를 테스트해보면서 다른 공개된 한국어 모델이나 데이터셋을 찾아봤는데, 잘 정리된 곳을 찾진 못해서 따로 정리해보면 좋을 것 같습니다.</li>
</ul>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="inahjeon/devlog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/devlog/2019/07/21/fasttext.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/devlog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/devlog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/devlog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/devlog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/devlog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
